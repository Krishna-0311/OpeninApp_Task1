{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag6QmjrdMFUj"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import numpy as np\n",
        "import moviepy.editor as mp\n",
        "import cv2\n",
        "\n",
        "# Load the video and audio files\n",
        "video_path = \"/content/TechNews 1562 __ IPL Final, OLA Prime Plus, Love scam, Motorola Edge 40, Premium TV Days Etc....mp4\"\n",
        "audio_path = \"/content/output10.wav\"\n",
        "\n",
        "\n",
        "# Load the face detector and landmarks predictor\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "landmarks_predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "# Load the video clip\n",
        "video_clip = mp.VideoFileClip(video_path)\n",
        "audio_clip = mp.AudioFileClip(audio_path)\n",
        "audio_clip = audio_clip.subclip(0, 67)\n",
        "# Get the fps of the video\n",
        "fps = video_clip.fps\n",
        "\n",
        "# Function to extract landmarks from a frame\n",
        "def get_landmarks(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detector(gray)\n",
        "    if faces:\n",
        "        landmarks = landmarks_predictor(gray, faces[0])\n",
        "        landmarks = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
        "        return landmarks\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Process video frames and synchronize with audio\n",
        "new_frames = []\n",
        "for idx, frame in enumerate(video_clip.iter_frames(fps=fps, dtype=\"uint8\")):\n",
        "    landmarks = get_landmarks(frame)\n",
        "    if landmarks is not None:\n",
        "        # Calculate audio amplitude at the current frame\n",
        "        start_time = idx / fps\n",
        "        end_time = (idx + 1) / fps\n",
        "        audio_amplitude = np.mean(audio_clip.subclip(start_time, end_time).to_soundarray())\n",
        "\n",
        "        # Modify lip landmarks based on audio amplitude (example: move lip landmarks up/down)\n",
        "        amplitude_modification = 10 * audio_amplitude  # Adjust the multiplier based on the effect you want\n",
        "        processed_landmarks = landmarks + amplitude_modification\n",
        "\n",
        "        # Create a new frame with modified landmarks\n",
        "        processed_frame = frame.copy()\n",
        "        for landmark in processed_landmarks:\n",
        "            x, y = landmark.astype(int)\n",
        "            cv2.circle(processed_frame, (x, y), 3, (0, 255, 0), -1)\n",
        "\n",
        "        # Add processed frame with modified landmarks\n",
        "        new_frames.append(processed_frame)\n",
        "    else:\n",
        "        new_frames.append(frame)\n",
        "\n",
        "# Create a new video with processed frames and original audio\n",
        "processed_video = mp.ImageSequenceClip(new_frames, fps=fps)\n",
        "processed_video = processed_video.set_audio(audio_clip)\n",
        "\n",
        "# Save the final lip-synced video\n",
        "processed_video.write_videofile(\"lip_synced_video.mp4\", codec=\"libx264\", audio_codec=\"aac\")\n"
      ]
    }
  ]
}